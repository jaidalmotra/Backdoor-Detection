{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#Importing Libraries","metadata":{"id":"RIkHohc_dFX6"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom keras.callbacks import TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import TensorBoard, ModelCheckpoint\nnum_classes = 10\nepochs = 300","metadata":{"id":"ZTJvq_51cpE7","execution":{"iopub.status.busy":"2023-10-21T18:44:15.928614Z","iopub.execute_input":"2023-10-21T18:44:15.928901Z","iopub.status.idle":"2023-10-21T18:44:15.936584Z","shell.execute_reply.started":"2023-10-21T18:44:15.928876Z","shell.execute_reply":"2023-10-21T18:44:15.935496Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#2 Getting the Dataset ready\n\n2.1 Read the Dataset","metadata":{"id":"2vv9EHGMdRrQ"}},{"cell_type":"code","source":"import os\n\n# List the contents of the directory\ndirectory = '/kaggle/input/road-sign-detection/road_sign_detection/train'\nprint(os.listdir(directory))","metadata":{"id":"zM-FGNRedzKn","execution":{"iopub.status.busy":"2023-10-21T18:37:50.398652Z","iopub.execute_input":"2023-10-21T18:37:50.399202Z","iopub.status.idle":"2023-10-21T18:37:50.407302Z","shell.execute_reply.started":"2023-10-21T18:37:50.399174Z","shell.execute_reply":"2023-10-21T18:37:50.406344Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['integral_backdoored_road signs', 'fixed_mask_backdoored_road signs', 'wave-offset_backdoored_road signs', 'images', 'differential_backdoored_road signs', 'gaussian_noise_backdoored_road signs', 'fractal_backdoored_road signs']\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image\nimport os\n\n# Define the directory path\ndirectory_path = '/kaggle/input/road-sign-detection/road_sign_detection/train'\n\n# List all files in the directory\nfile_names = os.listdir(directory_path)\n\n# Load images from the directory\nimages = []\nfor file_name in file_names:\n    if file_name.endswith('.png') or file_name.endswith('.jpg') or file_name.endswith('.jpeg'):\n        image_path = os.path.join(directory_path, file_name)\n        image = Image.open(image_path)\n        images.append(image)\n\n# Process the images as required\n# ...\n\n# Example: Showing the first image\nif images:\n    images[0].show()\nelse:\n    print(\"No images found in the directory.\")","metadata":{"id":"3_eGMGGZd3fU","execution":{"iopub.status.busy":"2023-10-21T18:37:50.408423Z","iopub.execute_input":"2023-10-21T18:37:50.408770Z","iopub.status.idle":"2023-10-21T18:37:50.418169Z","shell.execute_reply.started":"2023-10-21T18:37:50.408737Z","shell.execute_reply":"2023-10-21T18:37:50.417298Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"No images found in the directory.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Define the training parameters","metadata":{"id":"KL5R8hKbfhqX"}},{"cell_type":"code","source":"batch_size = 128\nnum_epochs = 300\nimage_size = (64, 64)\nnum_classes = 7","metadata":{"id":"aUUd8bU0fofr","execution":{"iopub.status.busy":"2023-10-21T18:45:31.626389Z","iopub.execute_input":"2023-10-21T18:45:31.627106Z","iopub.status.idle":"2023-10-21T18:45:31.631549Z","shell.execute_reply.started":"2023-10-21T18:45:31.627050Z","shell.execute_reply":"2023-10-21T18:45:31.630542Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Load the Resnet50 model","metadata":{"id":"GCX7PCU6ftQJ"}},{"cell_type":"code","source":"image_input = Input(shape=(64, 64, 3))\nresnet50 = ResNet50(include_top=False, weights='imagenet')","metadata":{"id":"CpevUK0XfvXX","execution":{"iopub.status.busy":"2023-10-21T18:45:34.869056Z","iopub.execute_input":"2023-10-21T18:45:34.869468Z","iopub.status.idle":"2023-10-21T18:45:36.901661Z","shell.execute_reply.started":"2023-10-21T18:45:34.869436Z","shell.execute_reply":"2023-10-21T18:45:36.900837Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Add a new classification layer","metadata":{"id":"ihDfQsFEf8tu"}},{"cell_type":"code","source":"x = resnet50(image_input)\nx = Flatten()(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\nclass_outputs = Dense(7, activation='softmax')(x)\n","metadata":{"id":"kt50fBb8f9yb","execution":{"iopub.status.busy":"2023-10-21T18:45:39.384604Z","iopub.execute_input":"2023-10-21T18:45:39.385374Z","iopub.status.idle":"2023-10-21T18:45:39.886450Z","shell.execute_reply.started":"2023-10-21T18:45:39.385336Z","shell.execute_reply":"2023-10-21T18:45:39.885452Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#Creating,training and testing the model","metadata":{"id":"ctXkLY43gLDN"}},{"cell_type":"code","source":"# Create the model\nmodel = Model(image_input, class_outputs)\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n\n# Load the training data\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n)\n\ntrain_dataset = train_datagen.flow_from_directory(\n    '/kaggle/input/road-sign-detection/road_sign_detection/train',\n    target_size=(64, 64),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n# Load the validation data\nval_datagen = ImageDataGenerator(rescale=1./255)\n\nval_dataset = val_datagen.flow_from_directory(\n    '/kaggle/input/road-sign-detection/road_sign_detection/val',\n    target_size=(64, 64),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n# Train the model\nmodel.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)\n\n# Evaluate the model on the test data\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_dataset = test_datagen.flow_from_directory(\n    '/kaggle/input/road-sign-detection/road_sign_detection/train',\n    target_size=(64, 64),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n","metadata":{"id":"S00KZS3Bek_s","execution":{"iopub.status.busy":"2023-10-21T18:50:15.022136Z","iopub.execute_input":"2023-10-21T18:50:15.022523Z","iopub.status.idle":"2023-10-21T21:14:56.546395Z","shell.execute_reply.started":"2023-10-21T18:50:15.022492Z","shell.execute_reply":"2023-10-21T21:14:56.545593Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Found 4291 images belonging to 7 classes.\nFound 622 images belonging to 7 classes.\nEpoch 1/300\n34/34 [==============================] - 88s 1s/step - loss: 1.9747 - accuracy: 0.2790 - val_loss: 1846.6710 - val_accuracy: 0.1431\nEpoch 2/300\n34/34 [==============================] - 29s 842ms/step - loss: 1.5771 - accuracy: 0.3116 - val_loss: 50.4983 - val_accuracy: 0.1431\nEpoch 3/300\n34/34 [==============================] - 29s 859ms/step - loss: 1.5168 - accuracy: 0.3354 - val_loss: 2.9940 - val_accuracy: 0.1431\nEpoch 4/300\n34/34 [==============================] - 29s 864ms/step - loss: 1.4240 - accuracy: 0.4048 - val_loss: 4.7372 - val_accuracy: 0.1495\nEpoch 5/300\n34/34 [==============================] - 28s 829ms/step - loss: 1.2825 - accuracy: 0.4642 - val_loss: 5.2650 - val_accuracy: 0.1431\nEpoch 6/300\n34/34 [==============================] - 29s 842ms/step - loss: 1.1851 - accuracy: 0.4885 - val_loss: 2.4507 - val_accuracy: 0.1431\nEpoch 7/300\n34/34 [==============================] - 29s 846ms/step - loss: 1.1400 - accuracy: 0.4901 - val_loss: 2.9395 - val_accuracy: 0.1431\nEpoch 8/300\n34/34 [==============================] - 29s 847ms/step - loss: 1.1073 - accuracy: 0.5057 - val_loss: 4.8409 - val_accuracy: 0.1479\nEpoch 9/300\n34/34 [==============================] - 29s 840ms/step - loss: 1.0127 - accuracy: 0.5213 - val_loss: 3.9410 - val_accuracy: 0.1431\nEpoch 10/300\n34/34 [==============================] - 29s 853ms/step - loss: 1.0172 - accuracy: 0.5292 - val_loss: 2.8471 - val_accuracy: 0.1495\nEpoch 11/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.9980 - accuracy: 0.5262 - val_loss: 2.5228 - val_accuracy: 0.1415\nEpoch 12/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.9645 - accuracy: 0.5334 - val_loss: 3.5239 - val_accuracy: 0.1447\nEpoch 13/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.9269 - accuracy: 0.5479 - val_loss: 3.5513 - val_accuracy: 0.1383\nEpoch 14/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.9779 - accuracy: 0.5332 - val_loss: 3.3463 - val_accuracy: 0.1399\nEpoch 15/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.9416 - accuracy: 0.5381 - val_loss: 3.7032 - val_accuracy: 0.1592\nEpoch 16/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.9270 - accuracy: 0.5407 - val_loss: 3.3628 - val_accuracy: 0.1383\nEpoch 17/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.9123 - accuracy: 0.5491 - val_loss: 3.6205 - val_accuracy: 0.1431\nEpoch 18/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.9085 - accuracy: 0.5598 - val_loss: 3.1054 - val_accuracy: 0.2637\nEpoch 19/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.9378 - accuracy: 0.5388 - val_loss: 4.8274 - val_accuracy: 0.1592\nEpoch 20/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.9140 - accuracy: 0.5407 - val_loss: 2.8998 - val_accuracy: 0.2830\nEpoch 21/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.9022 - accuracy: 0.5446 - val_loss: 4.7698 - val_accuracy: 0.1576\nEpoch 22/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.9356 - accuracy: 0.5498 - val_loss: 4.2030 - val_accuracy: 0.2878\nEpoch 23/300\n34/34 [==============================] - 29s 868ms/step - loss: 0.9054 - accuracy: 0.5421 - val_loss: 3.5437 - val_accuracy: 0.2830\nEpoch 24/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.9132 - accuracy: 0.5437 - val_loss: 5.6684 - val_accuracy: 0.1479\nEpoch 25/300\n34/34 [==============================] - 30s 880ms/step - loss: 0.8794 - accuracy: 0.5535 - val_loss: 6.1629 - val_accuracy: 0.1447\nEpoch 26/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8816 - accuracy: 0.5526 - val_loss: 5.8581 - val_accuracy: 0.1222\nEpoch 27/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8968 - accuracy: 0.5456 - val_loss: 4.5115 - val_accuracy: 0.1447\nEpoch 28/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8848 - accuracy: 0.5581 - val_loss: 6.2513 - val_accuracy: 0.1399\nEpoch 29/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8791 - accuracy: 0.5519 - val_loss: 5.7725 - val_accuracy: 0.1592\nEpoch 30/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8577 - accuracy: 0.5540 - val_loss: 6.4519 - val_accuracy: 0.1238\nEpoch 31/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8555 - accuracy: 0.5540 - val_loss: 5.3101 - val_accuracy: 0.1785\nEpoch 32/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8639 - accuracy: 0.5570 - val_loss: 4.4899 - val_accuracy: 0.1768\nEpoch 33/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8841 - accuracy: 0.5567 - val_loss: 1.3990 - val_accuracy: 0.5129\nEpoch 34/300\n34/34 [==============================] - 28s 828ms/step - loss: 0.8600 - accuracy: 0.5656 - val_loss: 2.4587 - val_accuracy: 0.3424\nEpoch 35/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8848 - accuracy: 0.5460 - val_loss: 2.5662 - val_accuracy: 0.3553\nEpoch 36/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8749 - accuracy: 0.5516 - val_loss: 2.3052 - val_accuracy: 0.3505\nEpoch 37/300\n34/34 [==============================] - 29s 837ms/step - loss: 0.8484 - accuracy: 0.5605 - val_loss: 5.4154 - val_accuracy: 0.3569\nEpoch 38/300\n34/34 [==============================] - 28s 821ms/step - loss: 0.8584 - accuracy: 0.5605 - val_loss: 1.6251 - val_accuracy: 0.4405\nEpoch 39/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8501 - accuracy: 0.5577 - val_loss: 0.9698 - val_accuracy: 0.5386\nEpoch 40/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8644 - accuracy: 0.5602 - val_loss: 2.8876 - val_accuracy: 0.3601\nEpoch 41/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8563 - accuracy: 0.5637 - val_loss: 1.1027 - val_accuracy: 0.5145\nEpoch 42/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8466 - accuracy: 0.5665 - val_loss: 1.7379 - val_accuracy: 0.4196\nEpoch 43/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.8592 - accuracy: 0.5560 - val_loss: 1.0118 - val_accuracy: 0.5273\nEpoch 44/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8287 - accuracy: 0.5642 - val_loss: 1.0337 - val_accuracy: 0.5064\nEpoch 45/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8361 - accuracy: 0.5598 - val_loss: 1.0807 - val_accuracy: 0.4968\nEpoch 46/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8279 - accuracy: 0.5644 - val_loss: 0.9990 - val_accuracy: 0.5193\nEpoch 47/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8667 - accuracy: 0.5621 - val_loss: 1.2626 - val_accuracy: 0.4646\nEpoch 48/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8420 - accuracy: 0.5609 - val_loss: 1.6674 - val_accuracy: 0.4277\nEpoch 49/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8972 - accuracy: 0.5549 - val_loss: 8.7235 - val_accuracy: 0.3424\nEpoch 50/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8473 - accuracy: 0.5598 - val_loss: 4.0208 - val_accuracy: 0.4228\nEpoch 51/300\n34/34 [==============================] - 28s 825ms/step - loss: 0.8436 - accuracy: 0.5633 - val_loss: 0.9078 - val_accuracy: 0.5273\nEpoch 52/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8305 - accuracy: 0.5549 - val_loss: 2.3536 - val_accuracy: 0.4035\nEpoch 53/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.8362 - accuracy: 0.5651 - val_loss: 1.8480 - val_accuracy: 0.4405\nEpoch 54/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8686 - accuracy: 0.5570 - val_loss: 3.0272 - val_accuracy: 0.4277\nEpoch 55/300\n34/34 [==============================] - 28s 827ms/step - loss: 0.8437 - accuracy: 0.5724 - val_loss: 3.5459 - val_accuracy: 0.2797\nEpoch 56/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8359 - accuracy: 0.5591 - val_loss: 1.4351 - val_accuracy: 0.4566\nEpoch 57/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8285 - accuracy: 0.5661 - val_loss: 1.4584 - val_accuracy: 0.4309\nEpoch 58/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8347 - accuracy: 0.5707 - val_loss: 2.0956 - val_accuracy: 0.4293\nEpoch 59/300\n34/34 [==============================] - 28s 827ms/step - loss: 0.8376 - accuracy: 0.5546 - val_loss: 2.9707 - val_accuracy: 0.3826\nEpoch 60/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8485 - accuracy: 0.5712 - val_loss: 5.8127 - val_accuracy: 0.3875\nEpoch 61/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8346 - accuracy: 0.5668 - val_loss: 3.0889 - val_accuracy: 0.3199\nEpoch 62/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8268 - accuracy: 0.5668 - val_loss: 2.1327 - val_accuracy: 0.4598\nEpoch 63/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8363 - accuracy: 0.5623 - val_loss: 1.3483 - val_accuracy: 0.4325\nEpoch 64/300\n34/34 [==============================] - 28s 825ms/step - loss: 0.8303 - accuracy: 0.5593 - val_loss: 0.8743 - val_accuracy: 0.5434\nEpoch 65/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8281 - accuracy: 0.5686 - val_loss: 1.4105 - val_accuracy: 0.4566\nEpoch 66/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.8431 - accuracy: 0.5600 - val_loss: 6.3299 - val_accuracy: 0.3859\nEpoch 67/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8221 - accuracy: 0.5626 - val_loss: 1.1875 - val_accuracy: 0.4775\nEpoch 68/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8358 - accuracy: 0.5619 - val_loss: 1.1349 - val_accuracy: 0.4904\nEpoch 69/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8243 - accuracy: 0.5600 - val_loss: 12.1020 - val_accuracy: 0.3376\nEpoch 70/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8566 - accuracy: 0.5637 - val_loss: 2.5252 - val_accuracy: 0.3167\nEpoch 71/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8532 - accuracy: 0.5544 - val_loss: 1.0117 - val_accuracy: 0.5241\nEpoch 72/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8347 - accuracy: 0.5658 - val_loss: 1.1990 - val_accuracy: 0.4871\nEpoch 73/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8405 - accuracy: 0.5668 - val_loss: 1.1143 - val_accuracy: 0.4871\nEpoch 74/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8371 - accuracy: 0.5663 - val_loss: 0.9224 - val_accuracy: 0.5370\nEpoch 75/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8182 - accuracy: 0.5675 - val_loss: 0.9589 - val_accuracy: 0.5209\nEpoch 76/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8365 - accuracy: 0.5654 - val_loss: 1.6657 - val_accuracy: 0.4566\nEpoch 77/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.8895 - accuracy: 0.5509 - val_loss: 5.8469 - val_accuracy: 0.3006\nEpoch 78/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8581 - accuracy: 0.5558 - val_loss: 3.0866 - val_accuracy: 0.3248\nEpoch 79/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8503 - accuracy: 0.5600 - val_loss: 9.4211 - val_accuracy: 0.4068\nEpoch 80/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.8230 - accuracy: 0.5719 - val_loss: 1.2491 - val_accuracy: 0.5322\nEpoch 81/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8228 - accuracy: 0.5649 - val_loss: 3.2959 - val_accuracy: 0.3199\nEpoch 82/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8364 - accuracy: 0.5740 - val_loss: 1.0567 - val_accuracy: 0.4968\nEpoch 83/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.8225 - accuracy: 0.5560 - val_loss: 3.4226 - val_accuracy: 0.3859\nEpoch 84/300\n34/34 [==============================] - 29s 862ms/step - loss: 1.1243 - accuracy: 0.5540 - val_loss: 4331566.0000 - val_accuracy: 0.1431\nEpoch 85/300\n34/34 [==============================] - 28s 829ms/step - loss: 1.6400 - accuracy: 0.2953 - val_loss: 296235712.0000 - val_accuracy: 0.1431\nEpoch 86/300\n34/34 [==============================] - 29s 845ms/step - loss: 1.5425 - accuracy: 0.3027 - val_loss: 1080659.1250 - val_accuracy: 0.1431\nEpoch 87/300\n34/34 [==============================] - 28s 828ms/step - loss: 1.5334 - accuracy: 0.3076 - val_loss: 40064.7148 - val_accuracy: 0.1495\nEpoch 88/300\n34/34 [==============================] - 28s 833ms/step - loss: 1.5193 - accuracy: 0.3195 - val_loss: 2211.6506 - val_accuracy: 0.2138\nEpoch 89/300\n34/34 [==============================] - 28s 825ms/step - loss: 1.5021 - accuracy: 0.3298 - val_loss: 29.0616 - val_accuracy: 0.2492\nEpoch 90/300\n34/34 [==============================] - 28s 836ms/step - loss: 1.4807 - accuracy: 0.3409 - val_loss: 1.6074 - val_accuracy: 0.3023\nEpoch 91/300\n34/34 [==============================] - 28s 834ms/step - loss: 1.4773 - accuracy: 0.3386 - val_loss: 1.7502 - val_accuracy: 0.2781\nEpoch 92/300\n34/34 [==============================] - 28s 833ms/step - loss: 1.4714 - accuracy: 0.3375 - val_loss: 1.5424 - val_accuracy: 0.2685\nEpoch 93/300\n34/34 [==============================] - 28s 832ms/step - loss: 1.4349 - accuracy: 0.3552 - val_loss: 1.6084 - val_accuracy: 0.2830\nEpoch 94/300\n34/34 [==============================] - 28s 832ms/step - loss: 1.4277 - accuracy: 0.3631 - val_loss: 1.6478 - val_accuracy: 0.2830\nEpoch 95/300\n34/34 [==============================] - 28s 833ms/step - loss: 1.4020 - accuracy: 0.3691 - val_loss: 1.6588 - val_accuracy: 0.2990\nEpoch 96/300\n34/34 [==============================] - 28s 832ms/step - loss: 1.3763 - accuracy: 0.3796 - val_loss: 1.6086 - val_accuracy: 0.2781\nEpoch 97/300\n34/34 [==============================] - 28s 830ms/step - loss: 1.3558 - accuracy: 0.3841 - val_loss: 1.4788 - val_accuracy: 0.3199\nEpoch 98/300\n34/34 [==============================] - 28s 828ms/step - loss: 1.3372 - accuracy: 0.3883 - val_loss: 1.4254 - val_accuracy: 0.3360\nEpoch 99/300\n34/34 [==============================] - 29s 845ms/step - loss: 1.3074 - accuracy: 0.4078 - val_loss: 1.5297 - val_accuracy: 0.3328\nEpoch 100/300\n34/34 [==============================] - 28s 829ms/step - loss: 1.2770 - accuracy: 0.4227 - val_loss: 1.5790 - val_accuracy: 0.3071\nEpoch 101/300\n34/34 [==============================] - 29s 839ms/step - loss: 1.2379 - accuracy: 0.4456 - val_loss: 1.6024 - val_accuracy: 0.3135\nEpoch 102/300\n34/34 [==============================] - 28s 829ms/step - loss: 1.2385 - accuracy: 0.4393 - val_loss: 1.3687 - val_accuracy: 0.3682\nEpoch 103/300\n34/34 [==============================] - 29s 856ms/step - loss: 1.1954 - accuracy: 0.4642 - val_loss: 1.4127 - val_accuracy: 0.3650\nEpoch 104/300\n34/34 [==============================] - 28s 831ms/step - loss: 1.1913 - accuracy: 0.4680 - val_loss: 1.5205 - val_accuracy: 0.3457\nEpoch 105/300\n34/34 [==============================] - 29s 841ms/step - loss: 1.1411 - accuracy: 0.4775 - val_loss: 1.6100 - val_accuracy: 0.3264\nEpoch 106/300\n34/34 [==============================] - 28s 836ms/step - loss: 1.0868 - accuracy: 0.5059 - val_loss: 1.8790 - val_accuracy: 0.3280\nEpoch 107/300\n34/34 [==============================] - 28s 838ms/step - loss: 1.0296 - accuracy: 0.5262 - val_loss: 1.9071 - val_accuracy: 0.3473\nEpoch 108/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.9923 - accuracy: 0.5223 - val_loss: 3.0718 - val_accuracy: 0.3585\nEpoch 109/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.9584 - accuracy: 0.5278 - val_loss: 1.3209 - val_accuracy: 0.4405\nEpoch 110/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.9132 - accuracy: 0.5507 - val_loss: 2.2495 - val_accuracy: 0.4244\nEpoch 111/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.9483 - accuracy: 0.5388 - val_loss: 1.9508 - val_accuracy: 0.4405\nEpoch 112/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.9098 - accuracy: 0.5362 - val_loss: 1.0550 - val_accuracy: 0.5064\nEpoch 113/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8798 - accuracy: 0.5467 - val_loss: 1.5508 - val_accuracy: 0.4678\nEpoch 114/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8876 - accuracy: 0.5479 - val_loss: 1.5277 - val_accuracy: 0.4920\nEpoch 115/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8779 - accuracy: 0.5535 - val_loss: 6.2301 - val_accuracy: 0.3264\nEpoch 116/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8748 - accuracy: 0.5491 - val_loss: 1.2945 - val_accuracy: 0.5064\nEpoch 117/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8701 - accuracy: 0.5533 - val_loss: 2.7834 - val_accuracy: 0.4100\nEpoch 118/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8753 - accuracy: 0.5495 - val_loss: 0.9148 - val_accuracy: 0.5289\nEpoch 119/300\n34/34 [==============================] - 28s 824ms/step - loss: 0.8523 - accuracy: 0.5479 - val_loss: 3.5627 - val_accuracy: 0.4244\nEpoch 120/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8513 - accuracy: 0.5540 - val_loss: 2.7647 - val_accuracy: 0.3039\nEpoch 121/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8724 - accuracy: 0.5598 - val_loss: 0.9245 - val_accuracy: 0.5563\nEpoch 122/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8567 - accuracy: 0.5570 - val_loss: 4.0969 - val_accuracy: 0.3971\nEpoch 123/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8551 - accuracy: 0.5560 - val_loss: 1.0810 - val_accuracy: 0.5145\nEpoch 124/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8475 - accuracy: 0.5537 - val_loss: 1.9050 - val_accuracy: 0.3971\nEpoch 125/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8493 - accuracy: 0.5619 - val_loss: 6.2375 - val_accuracy: 0.3778\nEpoch 126/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8547 - accuracy: 0.5546 - val_loss: 1.1600 - val_accuracy: 0.4871\nEpoch 127/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8457 - accuracy: 0.5586 - val_loss: 1.2402 - val_accuracy: 0.4646\nEpoch 128/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8437 - accuracy: 0.5586 - val_loss: 9.3584 - val_accuracy: 0.2942\nEpoch 129/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8378 - accuracy: 0.5614 - val_loss: 1.4078 - val_accuracy: 0.4598\nEpoch 130/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8393 - accuracy: 0.5609 - val_loss: 0.9455 - val_accuracy: 0.5498\nEpoch 131/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.8435 - accuracy: 0.5651 - val_loss: 1.8368 - val_accuracy: 0.4405\nEpoch 132/300\n34/34 [==============================] - 28s 822ms/step - loss: 0.8465 - accuracy: 0.5558 - val_loss: 1.1259 - val_accuracy: 0.5161\nEpoch 133/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8414 - accuracy: 0.5591 - val_loss: 9.4112 - val_accuracy: 0.2878\nEpoch 134/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8396 - accuracy: 0.5640 - val_loss: 1.0344 - val_accuracy: 0.5177\nEpoch 135/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8481 - accuracy: 0.5572 - val_loss: 1.6400 - val_accuracy: 0.4550\nEpoch 136/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8372 - accuracy: 0.5665 - val_loss: 1.1684 - val_accuracy: 0.5177\nEpoch 137/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8285 - accuracy: 0.5612 - val_loss: 1.1039 - val_accuracy: 0.4936\nEpoch 138/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8302 - accuracy: 0.5563 - val_loss: 0.9570 - val_accuracy: 0.5386\nEpoch 139/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8439 - accuracy: 0.5553 - val_loss: 0.9055 - val_accuracy: 0.5257\nEpoch 140/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8367 - accuracy: 0.5705 - val_loss: 1.3057 - val_accuracy: 0.5080\nEpoch 141/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8279 - accuracy: 0.5682 - val_loss: 1.8938 - val_accuracy: 0.4228\nEpoch 142/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8300 - accuracy: 0.5619 - val_loss: 12.6074 - val_accuracy: 0.3055\nEpoch 143/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8479 - accuracy: 0.5537 - val_loss: 2.2454 - val_accuracy: 0.3650\nEpoch 144/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8258 - accuracy: 0.5626 - val_loss: 1.0708 - val_accuracy: 0.5193\nEpoch 145/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8328 - accuracy: 0.5628 - val_loss: 6.3954 - val_accuracy: 0.3360\nEpoch 146/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8228 - accuracy: 0.5693 - val_loss: 4.0531 - val_accuracy: 0.3842\nEpoch 147/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8220 - accuracy: 0.5621 - val_loss: 2.0766 - val_accuracy: 0.4614\nEpoch 148/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8525 - accuracy: 0.5623 - val_loss: 2.2832 - val_accuracy: 0.4389\nEpoch 149/300\n34/34 [==============================] - 28s 828ms/step - loss: 0.8376 - accuracy: 0.5533 - val_loss: 0.9056 - val_accuracy: 0.5225\nEpoch 150/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8228 - accuracy: 0.5670 - val_loss: 1.8094 - val_accuracy: 0.4357\nEpoch 151/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8345 - accuracy: 0.5602 - val_loss: 1.4516 - val_accuracy: 0.4759\nEpoch 152/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8322 - accuracy: 0.5609 - val_loss: 2.4176 - val_accuracy: 0.4469\nEpoch 153/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8297 - accuracy: 0.5619 - val_loss: 4.1535 - val_accuracy: 0.4019\nEpoch 154/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8181 - accuracy: 0.5686 - val_loss: 1.2610 - val_accuracy: 0.5129\nEpoch 155/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8351 - accuracy: 0.5588 - val_loss: 2.5758 - val_accuracy: 0.3650\nEpoch 156/300\n34/34 [==============================] - 29s 871ms/step - loss: 0.8233 - accuracy: 0.5514 - val_loss: 1.2989 - val_accuracy: 0.4887\nEpoch 157/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8306 - accuracy: 0.5630 - val_loss: 0.9261 - val_accuracy: 0.5450\nEpoch 158/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8433 - accuracy: 0.5537 - val_loss: 6.6978 - val_accuracy: 0.3360\nEpoch 159/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8274 - accuracy: 0.5567 - val_loss: 0.9156 - val_accuracy: 0.5386\nEpoch 160/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8153 - accuracy: 0.5635 - val_loss: 1.3536 - val_accuracy: 0.4952\nEpoch 161/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8266 - accuracy: 0.5598 - val_loss: 3.2376 - val_accuracy: 0.4100\nEpoch 162/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8272 - accuracy: 0.5595 - val_loss: 4.5403 - val_accuracy: 0.3730\nEpoch 163/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8222 - accuracy: 0.5651 - val_loss: 2.0168 - val_accuracy: 0.4148\nEpoch 164/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8171 - accuracy: 0.5623 - val_loss: 1.5313 - val_accuracy: 0.4502\nEpoch 165/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8295 - accuracy: 0.5649 - val_loss: 1.0502 - val_accuracy: 0.5305\nEpoch 166/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8354 - accuracy: 0.5584 - val_loss: 1.8657 - val_accuracy: 0.4212\nEpoch 167/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8269 - accuracy: 0.5633 - val_loss: 0.8836 - val_accuracy: 0.5386\nEpoch 168/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.8226 - accuracy: 0.5567 - val_loss: 2.2999 - val_accuracy: 0.4325\nEpoch 169/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8332 - accuracy: 0.5668 - val_loss: 1.9961 - val_accuracy: 0.3955\nEpoch 170/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8263 - accuracy: 0.5658 - val_loss: 1.3989 - val_accuracy: 0.4775\nEpoch 171/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8250 - accuracy: 0.5689 - val_loss: 1.6352 - val_accuracy: 0.4486\nEpoch 172/300\n34/34 [==============================] - 28s 827ms/step - loss: 0.8270 - accuracy: 0.5560 - val_loss: 0.8625 - val_accuracy: 0.5498\nEpoch 173/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8239 - accuracy: 0.5614 - val_loss: 0.9918 - val_accuracy: 0.5386\nEpoch 174/300\n34/34 [==============================] - 28s 828ms/step - loss: 0.8264 - accuracy: 0.5693 - val_loss: 8.5837 - val_accuracy: 0.3810\nEpoch 175/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8230 - accuracy: 0.5682 - val_loss: 0.9505 - val_accuracy: 0.5434\nEpoch 176/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8137 - accuracy: 0.5726 - val_loss: 1.1147 - val_accuracy: 0.5064\nEpoch 177/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8178 - accuracy: 0.5644 - val_loss: 0.8933 - val_accuracy: 0.5402\nEpoch 178/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8194 - accuracy: 0.5598 - val_loss: 1.6503 - val_accuracy: 0.4518\nEpoch 179/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8128 - accuracy: 0.5703 - val_loss: 0.9436 - val_accuracy: 0.5531\nEpoch 180/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8120 - accuracy: 0.5651 - val_loss: 2.0987 - val_accuracy: 0.4148\nEpoch 181/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8286 - accuracy: 0.5649 - val_loss: 0.8963 - val_accuracy: 0.5402\nEpoch 182/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8446 - accuracy: 0.5633 - val_loss: 13.5278 - val_accuracy: 0.3055\nEpoch 183/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8231 - accuracy: 0.5679 - val_loss: 1.1935 - val_accuracy: 0.5225\nEpoch 184/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8199 - accuracy: 0.5689 - val_loss: 0.8896 - val_accuracy: 0.5322\nEpoch 185/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8176 - accuracy: 0.5579 - val_loss: 1.7695 - val_accuracy: 0.4293\nEpoch 186/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8133 - accuracy: 0.5689 - val_loss: 0.9436 - val_accuracy: 0.5482\nEpoch 187/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8130 - accuracy: 0.5591 - val_loss: 1.8541 - val_accuracy: 0.4196\nEpoch 188/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8143 - accuracy: 0.5717 - val_loss: 2.5500 - val_accuracy: 0.3408\nEpoch 189/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8180 - accuracy: 0.5635 - val_loss: 0.8667 - val_accuracy: 0.5627\nEpoch 190/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8172 - accuracy: 0.5556 - val_loss: 30.6103 - val_accuracy: 0.2894\nEpoch 191/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8208 - accuracy: 0.5607 - val_loss: 0.9506 - val_accuracy: 0.5402\nEpoch 192/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8174 - accuracy: 0.5682 - val_loss: 2.4177 - val_accuracy: 0.4486\nEpoch 193/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8226 - accuracy: 0.5738 - val_loss: 1.1622 - val_accuracy: 0.5016\nEpoch 194/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8458 - accuracy: 0.5661 - val_loss: 1.2933 - val_accuracy: 0.4887\nEpoch 195/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8275 - accuracy: 0.5768 - val_loss: 2.8568 - val_accuracy: 0.3312\nEpoch 196/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8187 - accuracy: 0.5616 - val_loss: 1.3715 - val_accuracy: 0.4791\nEpoch 197/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8167 - accuracy: 0.5619 - val_loss: 0.8950 - val_accuracy: 0.5466\nEpoch 198/300\n34/34 [==============================] - 29s 864ms/step - loss: 0.8292 - accuracy: 0.5626 - val_loss: 2.0635 - val_accuracy: 0.4486\nEpoch 199/300\n34/34 [==============================] - 29s 861ms/step - loss: 0.8183 - accuracy: 0.5619 - val_loss: 1.4123 - val_accuracy: 0.4630\nEpoch 200/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8214 - accuracy: 0.5633 - val_loss: 0.9803 - val_accuracy: 0.5482\nEpoch 201/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8262 - accuracy: 0.5703 - val_loss: 2.0059 - val_accuracy: 0.4469\nEpoch 202/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8179 - accuracy: 0.5649 - val_loss: 1.0843 - val_accuracy: 0.4904\nEpoch 203/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8307 - accuracy: 0.5656 - val_loss: 4.3751 - val_accuracy: 0.3392\nEpoch 204/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8295 - accuracy: 0.5572 - val_loss: 0.9108 - val_accuracy: 0.5402\nEpoch 205/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8165 - accuracy: 0.5647 - val_loss: 1.5187 - val_accuracy: 0.4887\nEpoch 206/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8284 - accuracy: 0.5658 - val_loss: 1.1113 - val_accuracy: 0.5080\nEpoch 207/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8215 - accuracy: 0.5654 - val_loss: 1.6406 - val_accuracy: 0.4469\nEpoch 208/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8149 - accuracy: 0.5693 - val_loss: 13.6660 - val_accuracy: 0.3006\nEpoch 209/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8158 - accuracy: 0.5698 - val_loss: 1.0609 - val_accuracy: 0.5193\nEpoch 210/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8140 - accuracy: 0.5651 - val_loss: 0.8586 - val_accuracy: 0.5579\nEpoch 211/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8221 - accuracy: 0.5705 - val_loss: 1.1009 - val_accuracy: 0.5016\nEpoch 212/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8133 - accuracy: 0.5642 - val_loss: 2.8360 - val_accuracy: 0.3183\nEpoch 213/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8100 - accuracy: 0.5623 - val_loss: 0.9451 - val_accuracy: 0.5514\nEpoch 214/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8311 - accuracy: 0.5577 - val_loss: 1.3514 - val_accuracy: 0.4662\nEpoch 215/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8254 - accuracy: 0.5591 - val_loss: 2.8753 - val_accuracy: 0.4051\nEpoch 216/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8183 - accuracy: 0.5656 - val_loss: 1.0458 - val_accuracy: 0.5305\nEpoch 217/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8142 - accuracy: 0.5696 - val_loss: 1.3961 - val_accuracy: 0.4502\nEpoch 218/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8635 - accuracy: 0.5640 - val_loss: 1.3068 - val_accuracy: 0.4566\nEpoch 219/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8294 - accuracy: 0.5689 - val_loss: 5.6715 - val_accuracy: 0.3360\nEpoch 220/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8140 - accuracy: 0.5612 - val_loss: 0.8556 - val_accuracy: 0.5563\nEpoch 221/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8184 - accuracy: 0.5686 - val_loss: 0.9111 - val_accuracy: 0.5434\nEpoch 222/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8218 - accuracy: 0.5703 - val_loss: 0.9023 - val_accuracy: 0.5466\nEpoch 223/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8188 - accuracy: 0.5626 - val_loss: 1.9293 - val_accuracy: 0.4871\nEpoch 224/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8250 - accuracy: 0.5591 - val_loss: 2.8341 - val_accuracy: 0.3746\nEpoch 225/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8307 - accuracy: 0.5591 - val_loss: 1.0765 - val_accuracy: 0.5113\nEpoch 226/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8216 - accuracy: 0.5684 - val_loss: 21.0454 - val_accuracy: 0.2910\nEpoch 227/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8243 - accuracy: 0.5698 - val_loss: 1.7107 - val_accuracy: 0.4132\nEpoch 228/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8132 - accuracy: 0.5635 - val_loss: 1.3220 - val_accuracy: 0.4453\nEpoch 229/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8295 - accuracy: 0.5707 - val_loss: 1.4687 - val_accuracy: 0.4357\nEpoch 230/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8183 - accuracy: 0.5763 - val_loss: 0.8780 - val_accuracy: 0.5643\nEpoch 231/300\n34/34 [==============================] - 28s 839ms/step - loss: 0.8179 - accuracy: 0.5693 - val_loss: 1.2895 - val_accuracy: 0.4695\nEpoch 232/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8166 - accuracy: 0.5663 - val_loss: 0.9142 - val_accuracy: 0.5257\nEpoch 233/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8112 - accuracy: 0.5644 - val_loss: 1.0207 - val_accuracy: 0.5241\nEpoch 234/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8094 - accuracy: 0.5626 - val_loss: 0.8693 - val_accuracy: 0.5563\nEpoch 235/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8098 - accuracy: 0.5766 - val_loss: 0.9185 - val_accuracy: 0.5370\nEpoch 236/300\n34/34 [==============================] - 28s 849ms/step - loss: 0.8127 - accuracy: 0.5628 - val_loss: 3.7896 - val_accuracy: 0.4035\nEpoch 237/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8111 - accuracy: 0.5670 - val_loss: 0.9482 - val_accuracy: 0.5482\nEpoch 238/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8164 - accuracy: 0.5595 - val_loss: 1.5880 - val_accuracy: 0.5113\nEpoch 239/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8166 - accuracy: 0.5637 - val_loss: 2.6847 - val_accuracy: 0.3505\nEpoch 240/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8199 - accuracy: 0.5693 - val_loss: 2.4560 - val_accuracy: 0.3682\nEpoch 241/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8322 - accuracy: 0.5595 - val_loss: 9.3050 - val_accuracy: 0.3183\nEpoch 242/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8191 - accuracy: 0.5675 - val_loss: 1.1370 - val_accuracy: 0.4984\nEpoch 243/300\n34/34 [==============================] - 28s 827ms/step - loss: 0.8117 - accuracy: 0.5682 - val_loss: 1.6753 - val_accuracy: 0.4357\nEpoch 244/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8123 - accuracy: 0.5595 - val_loss: 2.8461 - val_accuracy: 0.3505\nEpoch 245/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8237 - accuracy: 0.5649 - val_loss: 1.9015 - val_accuracy: 0.3875\nEpoch 246/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.8159 - accuracy: 0.5661 - val_loss: 1.0558 - val_accuracy: 0.5177\nEpoch 247/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.8186 - accuracy: 0.5600 - val_loss: 1.9223 - val_accuracy: 0.4244\nEpoch 248/300\n34/34 [==============================] - 28s 840ms/step - loss: 0.8343 - accuracy: 0.5630 - val_loss: 1.3054 - val_accuracy: 0.4887\nEpoch 249/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8267 - accuracy: 0.5528 - val_loss: 2.7367 - val_accuracy: 0.3232\nEpoch 250/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8185 - accuracy: 0.5714 - val_loss: 9.8749 - val_accuracy: 0.3264\nEpoch 251/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8163 - accuracy: 0.5607 - val_loss: 0.9607 - val_accuracy: 0.5402\nEpoch 252/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8203 - accuracy: 0.5586 - val_loss: 1.7282 - val_accuracy: 0.4421\nEpoch 253/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8207 - accuracy: 0.5698 - val_loss: 4.0088 - val_accuracy: 0.3859\nEpoch 254/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8135 - accuracy: 0.5663 - val_loss: 1.0736 - val_accuracy: 0.5064\nEpoch 255/300\n34/34 [==============================] - 30s 868ms/step - loss: 0.8127 - accuracy: 0.5658 - val_loss: 1.1123 - val_accuracy: 0.5000\nEpoch 256/300\n34/34 [==============================] - 30s 892ms/step - loss: 0.8082 - accuracy: 0.5752 - val_loss: 1.6202 - val_accuracy: 0.4421\nEpoch 257/300\n34/34 [==============================] - 31s 905ms/step - loss: 0.8079 - accuracy: 0.5740 - val_loss: 5.0189 - val_accuracy: 0.4019\nEpoch 258/300\n34/34 [==============================] - 30s 891ms/step - loss: 0.8425 - accuracy: 0.5649 - val_loss: 1.2843 - val_accuracy: 0.5113\nEpoch 259/300\n34/34 [==============================] - 30s 883ms/step - loss: 0.8264 - accuracy: 0.5563 - val_loss: 2.0772 - val_accuracy: 0.4309\nEpoch 260/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.8211 - accuracy: 0.5633 - val_loss: 53.5397 - val_accuracy: 0.2701\nEpoch 261/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8179 - accuracy: 0.5642 - val_loss: 2.7504 - val_accuracy: 0.3859\nEpoch 262/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8114 - accuracy: 0.5642 - val_loss: 1.1649 - val_accuracy: 0.5177\nEpoch 263/300\n34/34 [==============================] - 29s 836ms/step - loss: 0.8165 - accuracy: 0.5614 - val_loss: 2.1819 - val_accuracy: 0.3826\nEpoch 264/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8150 - accuracy: 0.5651 - val_loss: 2.6392 - val_accuracy: 0.4084\nEpoch 265/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8188 - accuracy: 0.5665 - val_loss: 1.4352 - val_accuracy: 0.4952\nEpoch 266/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.8172 - accuracy: 0.5721 - val_loss: 1.8870 - val_accuracy: 0.4035\nEpoch 267/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8151 - accuracy: 0.5761 - val_loss: 2.3150 - val_accuracy: 0.3650\nEpoch 268/300\n34/34 [==============================] - 28s 824ms/step - loss: 0.8061 - accuracy: 0.5710 - val_loss: 2.0504 - val_accuracy: 0.3987\nEpoch 269/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8143 - accuracy: 0.5649 - val_loss: 6.2439 - val_accuracy: 0.3585\nEpoch 270/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8222 - accuracy: 0.5679 - val_loss: 3.3991 - val_accuracy: 0.3392\nEpoch 271/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8186 - accuracy: 0.5668 - val_loss: 2.4522 - val_accuracy: 0.4325\nEpoch 272/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8148 - accuracy: 0.5654 - val_loss: 1.1781 - val_accuracy: 0.4984\nEpoch 273/300\n34/34 [==============================] - 28s 831ms/step - loss: 0.8148 - accuracy: 0.5663 - val_loss: 0.9031 - val_accuracy: 0.5531\nEpoch 274/300\n34/34 [==============================] - 28s 839ms/step - loss: 0.8046 - accuracy: 0.5705 - val_loss: 1.9310 - val_accuracy: 0.3971\nEpoch 275/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8086 - accuracy: 0.5717 - val_loss: 0.8747 - val_accuracy: 0.5547\nEpoch 276/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8149 - accuracy: 0.5689 - val_loss: 2.5588 - val_accuracy: 0.4759\nEpoch 277/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8127 - accuracy: 0.5644 - val_loss: 2.6062 - val_accuracy: 0.3939\nEpoch 278/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8136 - accuracy: 0.5712 - val_loss: 2.2967 - val_accuracy: 0.4148\nEpoch 279/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8177 - accuracy: 0.5668 - val_loss: 6.2764 - val_accuracy: 0.3859\nEpoch 280/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8191 - accuracy: 0.5649 - val_loss: 17.1364 - val_accuracy: 0.2942\nEpoch 281/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8254 - accuracy: 0.5621 - val_loss: 2.0648 - val_accuracy: 0.4293\nEpoch 282/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8154 - accuracy: 0.5714 - val_loss: 0.8784 - val_accuracy: 0.5595\nEpoch 283/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8166 - accuracy: 0.5679 - val_loss: 1.2074 - val_accuracy: 0.5225\nEpoch 284/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8086 - accuracy: 0.5735 - val_loss: 0.9685 - val_accuracy: 0.5370\nEpoch 285/300\n34/34 [==============================] - 28s 842ms/step - loss: 0.8056 - accuracy: 0.5724 - val_loss: 0.8677 - val_accuracy: 0.5402\nEpoch 286/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8100 - accuracy: 0.5735 - val_loss: 2.1662 - val_accuracy: 0.3553\nEpoch 287/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8222 - accuracy: 0.5633 - val_loss: 1.1638 - val_accuracy: 0.5209\nEpoch 288/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8099 - accuracy: 0.5703 - val_loss: 4.0857 - val_accuracy: 0.4051\nEpoch 289/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8126 - accuracy: 0.5726 - val_loss: 4.4863 - val_accuracy: 0.2476\nEpoch 290/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8120 - accuracy: 0.5661 - val_loss: 1.7166 - val_accuracy: 0.4228\nEpoch 291/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8168 - accuracy: 0.5693 - val_loss: 7.3989 - val_accuracy: 0.3232\nEpoch 292/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8079 - accuracy: 0.5733 - val_loss: 5.4572 - val_accuracy: 0.3473\nEpoch 293/300\n34/34 [==============================] - 28s 845ms/step - loss: 0.8080 - accuracy: 0.5679 - val_loss: 1.2100 - val_accuracy: 0.4727\nEpoch 294/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8076 - accuracy: 0.5768 - val_loss: 0.8916 - val_accuracy: 0.5289\nEpoch 295/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8089 - accuracy: 0.5726 - val_loss: 10.4215 - val_accuracy: 0.3344\nEpoch 296/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8080 - accuracy: 0.5644 - val_loss: 4.4992 - val_accuracy: 0.4244\nEpoch 297/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8249 - accuracy: 0.5621 - val_loss: 3.2597 - val_accuracy: 0.3199\nEpoch 298/300\n34/34 [==============================] - 28s 821ms/step - loss: 0.8328 - accuracy: 0.5628 - val_loss: 2.9904 - val_accuracy: 0.2974\nEpoch 299/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8237 - accuracy: 0.5719 - val_loss: 8.4853 - val_accuracy: 0.3810\nEpoch 300/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8113 - accuracy: 0.5710 - val_loss: 2.8898 - val_accuracy: 0.3344\nFound 4291 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Final testing accuracy","metadata":{"id":"jRY4ohtKtIA5"}},{"cell_type":"code","source":"# Perform prediction and evaluate the model\nfrom sklearn.metrics import classification_report\nimport time\n\ntest_labels = test_dataset.classes\ntest_labels = to_categorical(test_labels, num_classes=9)\n\nstart_time = time.time()\ny_pred = model.predict_generator(test_dataset)\ny_pred_bool = np.argmax(y_pred, axis=1)\nrounded_labels = np.argmax(test_labels, axis=1)\nprint(classification_report(y_pred_bool, rounded_labels, digits=4))\nprint(\"Time taken to predict the model: \" + str(time.time() - start_time))\n","metadata":{"id":"hgr6yztNtM5S","execution":{"iopub.status.busy":"2023-10-21T21:20:45.127689Z","iopub.execute_input":"2023-10-21T21:20:45.128432Z","iopub.status.idle":"2023-10-21T21:21:06.387593Z","shell.execute_reply.started":"2023-10-21T21:20:45.128398Z","shell.execute_reply":"2023-10-21T21:21:06.386440Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.0033    0.0952    0.0063        21\n           1     0.0571    0.1489    0.0825       235\n           2     0.1485    0.1396    0.1439       652\n           3     0.0212    0.2653    0.0393        49\n           4     0.6509    0.1491    0.2426      2676\n           5     0.0114    0.3182    0.0220        22\n           6     0.1599    0.1541    0.1569       636\n\n    accuracy                         0.1503      4291\n   macro avg     0.1503    0.1815    0.0991      4291\nweighted avg     0.4556    0.1503    0.2015      4291\n\nTime taken to predict the model: 21.251965761184692\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\n\n# Assuming 'model' is your trained model\n# Train your model before saving it as a pickle file\n\n# Save the model as a pickle file\nwith open('model.pkl', 'wb') as file:\n    pickle.dump(model, file)\n\nwith open('model.pkl', 'rb') as file:\n    loaded_model = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-10-21T21:21:13.946349Z","iopub.execute_input":"2023-10-21T21:21:13.946987Z","iopub.status.idle":"2023-10-21T21:21:36.633718Z","shell.execute_reply.started":"2023-10-21T21:21:13.946950Z","shell.execute_reply":"2023-10-21T21:21:36.632663Z"},"trusted":true},"execution_count":30,"outputs":[]}]}
