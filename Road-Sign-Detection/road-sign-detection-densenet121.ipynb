{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#Importing Libraries","metadata":{"id":"RIkHohc_dFX6"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.models import Model\nnum_classes = 10\nepochs = 300","metadata":{"id":"ZTJvq_51cpE7","execution":{"iopub.status.busy":"2023-10-21T23:03:59.188809Z","iopub.execute_input":"2023-10-21T23:03:59.189619Z","iopub.status.idle":"2023-10-21T23:04:07.102529Z","shell.execute_reply.started":"2023-10-21T23:03:59.189562Z","shell.execute_reply":"2023-10-21T23:04:07.101725Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#2 Getting the Dataset ready\n\n2.1 Read the Dataset","metadata":{"id":"2vv9EHGMdRrQ"}},{"cell_type":"code","source":"import os\n\n# List the contents of the directory\ndirectory = '/kaggle/input/road-sign-detection/road_sign_detection/train'\nprint(os.listdir(directory))","metadata":{"id":"zM-FGNRedzKn","execution":{"iopub.status.busy":"2023-10-21T23:04:07.104060Z","iopub.execute_input":"2023-10-21T23:04:07.104607Z","iopub.status.idle":"2023-10-21T23:04:07.114829Z","shell.execute_reply.started":"2023-10-21T23:04:07.104562Z","shell.execute_reply":"2023-10-21T23:04:07.113874Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['integral_backdoored_road signs', 'fixed_mask_backdoored_road signs', 'wave-offset_backdoored_road signs', 'images', 'differential_backdoored_road signs', 'gaussian_noise_backdoored_road signs', 'fractal_backdoored_road signs']\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image\nimport os\n\n# Define the directory path\ndirectory_path = '/kaggle/input/road-sign-detection/road_sign_detection/train'\n\n# List all files in the directory\nfile_names = os.listdir(directory_path)\n\n# Load images from the directory\nimages = []\nfor file_name in file_names:\n    if file_name.endswith('.png') or file_name.endswith('.jpg') or file_name.endswith('.jpeg'):\n        image_path = os.path.join(directory_path, file_name)\n        image = Image.open(image_path)\n        images.append(image)\n\n# Process the images as required\n# ...\n\n# Example: Showing the first image\nif images:\n    images[0].show()\nelse:\n    print(\"No images found in the directory.\")","metadata":{"id":"3_eGMGGZd3fU","execution":{"iopub.status.busy":"2023-10-21T23:04:07.116059Z","iopub.execute_input":"2023-10-21T23:04:07.116385Z","iopub.status.idle":"2023-10-21T23:04:07.123828Z","shell.execute_reply.started":"2023-10-21T23:04:07.116359Z","shell.execute_reply":"2023-10-21T23:04:07.122810Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"No images found in the directory.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Define the training parameters","metadata":{"id":"KL5R8hKbfhqX"}},{"cell_type":"code","source":"batch_size = 128\nnum_epochs = 300\nimage_size = (64, 64)\nnum_classes = 7","metadata":{"id":"aUUd8bU0fofr","execution":{"iopub.status.busy":"2023-10-21T23:04:07.126235Z","iopub.execute_input":"2023-10-21T23:04:07.127280Z","iopub.status.idle":"2023-10-21T23:04:07.132091Z","shell.execute_reply.started":"2023-10-21T23:04:07.127249Z","shell.execute_reply":"2023-10-21T23:04:07.131056Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Load the Densenet201 model","metadata":{"id":"GCX7PCU6ftQJ"}},{"cell_type":"code","source":"# Load the DenseNet201 model\nimage_input = Input(shape=(64, 64, 3))  # Adjust the shape according to the model's expected input shape\ndensenet121 = DenseNet121(include_top=False, weights='imagenet', input_tensor=image_input)","metadata":{"id":"CpevUK0XfvXX","execution":{"iopub.status.busy":"2023-10-21T23:04:07.133132Z","iopub.execute_input":"2023-10-21T23:04:07.133408Z","iopub.status.idle":"2023-10-21T23:04:16.107443Z","shell.execute_reply.started":"2023-10-21T23:04:07.133383Z","shell.execute_reply":"2023-10-21T23:04:16.106631Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n29084464/29084464 [==============================] - 2s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Add a new classification layer","metadata":{"id":"ihDfQsFEf8tu"}},{"cell_type":"code","source":"# Add a new classification layer\nx = densenet121.output\nx = Flatten()(x)  # Ensure that the output shape here is defined\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\nclass_outputs = Dense(7, activation='softmax')(x)\n\n# Create the model\nmodel = Model(inputs=densenet121.input, outputs=class_outputs)\n","metadata":{"id":"kt50fBb8f9yb","execution":{"iopub.status.busy":"2023-10-21T23:04:16.108595Z","iopub.execute_input":"2023-10-21T23:04:16.108904Z","iopub.status.idle":"2023-10-21T23:04:16.178495Z","shell.execute_reply.started":"2023-10-21T23:04:16.108878Z","shell.execute_reply":"2023-10-21T23:04:16.177651Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#Creating,training and testing the model","metadata":{"id":"ctXkLY43gLDN"}},{"cell_type":"code","source":"# Create the model\nmodel = Model(image_input, class_outputs)\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n\n# Load the training data\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n)\n\ntrain_dataset = train_datagen.flow_from_directory(\n    '/kaggle/input/road-sign-detection/road_sign_detection/train',\n    target_size=(64, 64),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n# Load the validation data\nval_datagen = ImageDataGenerator(rescale=1./255)\n\nval_dataset = val_datagen.flow_from_directory(\n    '/kaggle/input/road-sign-detection/road_sign_detection/val',\n    target_size=(64, 64),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\n# Train the model\nmodel.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)\n\n# Evaluate the model on the test data\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_dataset = test_datagen.flow_from_directory(\n    '/kaggle/input/road-sign-detection/road_sign_detection/train',\n    target_size=(64, 64),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n","metadata":{"id":"72Xr25nDzd_1","execution":{"iopub.status.busy":"2023-10-21T23:04:16.179755Z","iopub.execute_input":"2023-10-21T23:04:16.180040Z","iopub.status.idle":"2023-10-22T01:31:34.052942Z","shell.execute_reply.started":"2023-10-21T23:04:16.180015Z","shell.execute_reply":"2023-10-22T01:31:34.052168Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 4291 images belonging to 7 classes.\nFound 622 images belonging to 7 classes.\nEpoch 1/300\n34/34 [==============================] - 126s 1s/step - loss: 1.7990 - accuracy: 0.2887 - val_loss: 161.4810 - val_accuracy: 0.1431\nEpoch 2/300\n34/34 [==============================] - 30s 868ms/step - loss: 1.5838 - accuracy: 0.2974 - val_loss: 21.1376 - val_accuracy: 0.1543\nEpoch 3/300\n34/34 [==============================] - 30s 867ms/step - loss: 1.5689 - accuracy: 0.2920 - val_loss: 1.5956 - val_accuracy: 0.2862\nEpoch 4/300\n34/34 [==============================] - 30s 870ms/step - loss: 1.5402 - accuracy: 0.3109 - val_loss: 1.5858 - val_accuracy: 0.2862\nEpoch 5/300\n34/34 [==============================] - 29s 865ms/step - loss: 1.4418 - accuracy: 0.3589 - val_loss: 1.6575 - val_accuracy: 0.2974\nEpoch 6/300\n34/34 [==============================] - 30s 873ms/step - loss: 1.3614 - accuracy: 0.3876 - val_loss: 2.7809 - val_accuracy: 0.3360\nEpoch 7/300\n34/34 [==============================] - 30s 876ms/step - loss: 1.3691 - accuracy: 0.3990 - val_loss: 8.0596 - val_accuracy: 0.3055\nEpoch 8/300\n34/34 [==============================] - 30s 867ms/step - loss: 1.3601 - accuracy: 0.3983 - val_loss: 4.1258 - val_accuracy: 0.2508\nEpoch 9/300\n34/34 [==============================] - 29s 854ms/step - loss: 1.2209 - accuracy: 0.4607 - val_loss: 2.8549 - val_accuracy: 0.3408\nEpoch 10/300\n34/34 [==============================] - 29s 865ms/step - loss: 1.1233 - accuracy: 0.4894 - val_loss: 1.5428 - val_accuracy: 0.4887\nEpoch 11/300\n34/34 [==============================] - 30s 871ms/step - loss: 1.1091 - accuracy: 0.5015 - val_loss: 19.7495 - val_accuracy: 0.2283\nEpoch 12/300\n34/34 [==============================] - 29s 863ms/step - loss: 1.0693 - accuracy: 0.5036 - val_loss: 22.8328 - val_accuracy: 0.3489\nEpoch 13/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.9769 - accuracy: 0.5216 - val_loss: 2.1208 - val_accuracy: 0.4068\nEpoch 14/300\n34/34 [==============================] - 29s 861ms/step - loss: 1.0126 - accuracy: 0.5129 - val_loss: 4.3396 - val_accuracy: 0.3489\nEpoch 15/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.9589 - accuracy: 0.5234 - val_loss: 2.2743 - val_accuracy: 0.4051\nEpoch 16/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.9312 - accuracy: 0.5383 - val_loss: 1.5821 - val_accuracy: 0.4325\nEpoch 17/300\n34/34 [==============================] - 30s 874ms/step - loss: 0.9047 - accuracy: 0.5458 - val_loss: 2.0177 - val_accuracy: 0.4228\nEpoch 18/300\n34/34 [==============================] - 29s 862ms/step - loss: 0.9769 - accuracy: 0.5316 - val_loss: 1.1301 - val_accuracy: 0.5064\nEpoch 19/300\n34/34 [==============================] - 29s 867ms/step - loss: 0.9531 - accuracy: 0.5365 - val_loss: 1.9922 - val_accuracy: 0.4405\nEpoch 20/300\n34/34 [==============================] - 29s 865ms/step - loss: 0.9440 - accuracy: 0.5339 - val_loss: 3.5623 - val_accuracy: 0.4437\nEpoch 21/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.9520 - accuracy: 0.5442 - val_loss: 12.1409 - val_accuracy: 0.3842\nEpoch 22/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.9059 - accuracy: 0.5467 - val_loss: 0.9665 - val_accuracy: 0.5193\nEpoch 23/300\n34/34 [==============================] - 29s 861ms/step - loss: 0.8671 - accuracy: 0.5614 - val_loss: 1.4042 - val_accuracy: 0.4614\nEpoch 24/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.9106 - accuracy: 0.5502 - val_loss: 1.5859 - val_accuracy: 0.4904\nEpoch 25/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8933 - accuracy: 0.5546 - val_loss: 1.2279 - val_accuracy: 0.4855\nEpoch 26/300\n34/34 [==============================] - 29s 861ms/step - loss: 0.8945 - accuracy: 0.5516 - val_loss: 1.1317 - val_accuracy: 0.4936\nEpoch 27/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8800 - accuracy: 0.5609 - val_loss: 5.6114 - val_accuracy: 0.2910\nEpoch 28/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8751 - accuracy: 0.5470 - val_loss: 1.2244 - val_accuracy: 0.4791\nEpoch 29/300\n34/34 [==============================] - 29s 862ms/step - loss: 0.8803 - accuracy: 0.5481 - val_loss: 1.5534 - val_accuracy: 0.4711\nEpoch 30/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8543 - accuracy: 0.5565 - val_loss: 1.2687 - val_accuracy: 0.4920\nEpoch 31/300\n34/34 [==============================] - 29s 865ms/step - loss: 0.8787 - accuracy: 0.5491 - val_loss: 5.4742 - val_accuracy: 0.4196\nEpoch 32/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8750 - accuracy: 0.5470 - val_loss: 1.3577 - val_accuracy: 0.4566\nEpoch 33/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8654 - accuracy: 0.5491 - val_loss: 1.7319 - val_accuracy: 0.4325\nEpoch 34/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8875 - accuracy: 0.5546 - val_loss: 1.0251 - val_accuracy: 0.5386\nEpoch 35/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8420 - accuracy: 0.5600 - val_loss: 1.3376 - val_accuracy: 0.4598\nEpoch 36/300\n34/34 [==============================] - 30s 873ms/step - loss: 0.8627 - accuracy: 0.5593 - val_loss: 2.3754 - val_accuracy: 0.4936\nEpoch 37/300\n34/34 [==============================] - 31s 899ms/step - loss: 0.9042 - accuracy: 0.5591 - val_loss: 20.2693 - val_accuracy: 0.2717\nEpoch 38/300\n34/34 [==============================] - 30s 896ms/step - loss: 0.9326 - accuracy: 0.5411 - val_loss: 22.4016 - val_accuracy: 0.4212\nEpoch 39/300\n34/34 [==============================] - 31s 899ms/step - loss: 0.8932 - accuracy: 0.5537 - val_loss: 10.8482 - val_accuracy: 0.3842\nEpoch 40/300\n34/34 [==============================] - 30s 877ms/step - loss: 0.8550 - accuracy: 0.5540 - val_loss: 0.8566 - val_accuracy: 0.5691\nEpoch 41/300\n34/34 [==============================] - 30s 871ms/step - loss: 0.8476 - accuracy: 0.5558 - val_loss: 1.2304 - val_accuracy: 0.5241\nEpoch 42/300\n34/34 [==============================] - 29s 865ms/step - loss: 0.8827 - accuracy: 0.5600 - val_loss: 3.7860 - val_accuracy: 0.4084\nEpoch 43/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8556 - accuracy: 0.5586 - val_loss: 1.0248 - val_accuracy: 0.5161\nEpoch 44/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.8820 - accuracy: 0.5509 - val_loss: 2.1790 - val_accuracy: 0.4148\nEpoch 45/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8578 - accuracy: 0.5509 - val_loss: 1.3615 - val_accuracy: 0.4678\nEpoch 46/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8445 - accuracy: 0.5577 - val_loss: 1.1294 - val_accuracy: 0.5177\nEpoch 47/300\n34/34 [==============================] - 30s 869ms/step - loss: 0.8495 - accuracy: 0.5544 - val_loss: 3.1357 - val_accuracy: 0.4035\nEpoch 48/300\n34/34 [==============================] - 30s 884ms/step - loss: 0.8408 - accuracy: 0.5738 - val_loss: 1.2363 - val_accuracy: 0.5032\nEpoch 49/300\n34/34 [==============================] - 30s 872ms/step - loss: 0.8390 - accuracy: 0.5602 - val_loss: 0.9427 - val_accuracy: 0.5434\nEpoch 50/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8465 - accuracy: 0.5584 - val_loss: 8.1909 - val_accuracy: 0.3746\nEpoch 51/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8456 - accuracy: 0.5609 - val_loss: 1.5185 - val_accuracy: 0.4437\nEpoch 52/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8463 - accuracy: 0.5572 - val_loss: 1.3966 - val_accuracy: 0.4807\nEpoch 53/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8417 - accuracy: 0.5588 - val_loss: 1.2152 - val_accuracy: 0.5322\nEpoch 54/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8423 - accuracy: 0.5696 - val_loss: 0.9318 - val_accuracy: 0.5466\nEpoch 55/300\n34/34 [==============================] - 30s 875ms/step - loss: 0.8424 - accuracy: 0.5574 - val_loss: 5.6206 - val_accuracy: 0.4373\nEpoch 56/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.8425 - accuracy: 0.5540 - val_loss: 11.8308 - val_accuracy: 0.3248\nEpoch 57/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8420 - accuracy: 0.5570 - val_loss: 0.9196 - val_accuracy: 0.5354\nEpoch 58/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8330 - accuracy: 0.5700 - val_loss: 2.5616 - val_accuracy: 0.4646\nEpoch 59/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8301 - accuracy: 0.5707 - val_loss: 0.9047 - val_accuracy: 0.5707\nEpoch 60/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8426 - accuracy: 0.5616 - val_loss: 4.9733 - val_accuracy: 0.3489\nEpoch 61/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8456 - accuracy: 0.5644 - val_loss: 1.0257 - val_accuracy: 0.5338\nEpoch 62/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8296 - accuracy: 0.5703 - val_loss: 1.0196 - val_accuracy: 0.5273\nEpoch 63/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8369 - accuracy: 0.5553 - val_loss: 0.8858 - val_accuracy: 0.5466\nEpoch 64/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8379 - accuracy: 0.5691 - val_loss: 1.2064 - val_accuracy: 0.5080\nEpoch 65/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8307 - accuracy: 0.5672 - val_loss: 2.0762 - val_accuracy: 0.5225\nEpoch 66/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8294 - accuracy: 0.5628 - val_loss: 0.9507 - val_accuracy: 0.5402\nEpoch 67/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8244 - accuracy: 0.5668 - val_loss: 3.8317 - val_accuracy: 0.4502\nEpoch 68/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8398 - accuracy: 0.5626 - val_loss: 0.9894 - val_accuracy: 0.5370\nEpoch 69/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8671 - accuracy: 0.5472 - val_loss: 1.8685 - val_accuracy: 0.4100\nEpoch 70/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8466 - accuracy: 0.5588 - val_loss: 0.9787 - val_accuracy: 0.5241\nEpoch 71/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8325 - accuracy: 0.5607 - val_loss: 4.9508 - val_accuracy: 0.3891\nEpoch 72/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8264 - accuracy: 0.5586 - val_loss: 1.0480 - val_accuracy: 0.5193\nEpoch 73/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8489 - accuracy: 0.5684 - val_loss: 3.3054 - val_accuracy: 0.4453\nEpoch 74/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8298 - accuracy: 0.5658 - val_loss: 1.5441 - val_accuracy: 0.4662\nEpoch 75/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8169 - accuracy: 0.5642 - val_loss: 2.5482 - val_accuracy: 0.4164\nEpoch 76/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8245 - accuracy: 0.5637 - val_loss: 0.8472 - val_accuracy: 0.5595\nEpoch 77/300\n34/34 [==============================] - 28s 838ms/step - loss: 0.8280 - accuracy: 0.5665 - val_loss: 6.9759 - val_accuracy: 0.3987\nEpoch 78/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8206 - accuracy: 0.5735 - val_loss: 2.8042 - val_accuracy: 0.4164\nEpoch 79/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8275 - accuracy: 0.5656 - val_loss: 0.8388 - val_accuracy: 0.5595\nEpoch 80/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8269 - accuracy: 0.5588 - val_loss: 0.8982 - val_accuracy: 0.5305\nEpoch 81/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8303 - accuracy: 0.5595 - val_loss: 1.2359 - val_accuracy: 0.5225\nEpoch 82/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8357 - accuracy: 0.5672 - val_loss: 8.1046 - val_accuracy: 0.3714\nEpoch 83/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8370 - accuracy: 0.5647 - val_loss: 3.6782 - val_accuracy: 0.3891\nEpoch 84/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8229 - accuracy: 0.5658 - val_loss: 0.8952 - val_accuracy: 0.5531\nEpoch 85/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8179 - accuracy: 0.5628 - val_loss: 31.6666 - val_accuracy: 0.2717\nEpoch 86/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8270 - accuracy: 0.5588 - val_loss: 0.8622 - val_accuracy: 0.5675\nEpoch 87/300\n34/34 [==============================] - 29s 836ms/step - loss: 0.8151 - accuracy: 0.5696 - val_loss: 2.5338 - val_accuracy: 0.4807\nEpoch 88/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8264 - accuracy: 0.5658 - val_loss: 2.1215 - val_accuracy: 0.4196\nEpoch 89/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8230 - accuracy: 0.5574 - val_loss: 3.8243 - val_accuracy: 0.4309\nEpoch 90/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8571 - accuracy: 0.5593 - val_loss: 21.7654 - val_accuracy: 0.1656\nEpoch 91/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8954 - accuracy: 0.5516 - val_loss: 149.4881 - val_accuracy: 0.3167\nEpoch 92/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8785 - accuracy: 0.5470 - val_loss: 12.6682 - val_accuracy: 0.5032\nEpoch 93/300\n34/34 [==============================] - 28s 832ms/step - loss: 0.8483 - accuracy: 0.5607 - val_loss: 1.1410 - val_accuracy: 0.5273\nEpoch 94/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8528 - accuracy: 0.5637 - val_loss: 1.0056 - val_accuracy: 0.5402\nEpoch 95/300\n34/34 [==============================] - 28s 830ms/step - loss: 0.8221 - accuracy: 0.5700 - val_loss: 5.9376 - val_accuracy: 0.4212\nEpoch 96/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8289 - accuracy: 0.5630 - val_loss: 2.3231 - val_accuracy: 0.4727\nEpoch 97/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8318 - accuracy: 0.5630 - val_loss: 0.9389 - val_accuracy: 0.5257\nEpoch 98/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.8268 - accuracy: 0.5684 - val_loss: 1.4179 - val_accuracy: 0.4823\nEpoch 99/300\n34/34 [==============================] - 30s 867ms/step - loss: 0.8220 - accuracy: 0.5682 - val_loss: 9.4500 - val_accuracy: 0.3810\nEpoch 100/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8384 - accuracy: 0.5668 - val_loss: 3.0555 - val_accuracy: 0.4582\nEpoch 101/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8271 - accuracy: 0.5658 - val_loss: 1.9651 - val_accuracy: 0.4662\nEpoch 102/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8294 - accuracy: 0.5586 - val_loss: 1.0427 - val_accuracy: 0.5386\nEpoch 103/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8257 - accuracy: 0.5647 - val_loss: 0.8245 - val_accuracy: 0.5707\nEpoch 104/300\n34/34 [==============================] - 28s 826ms/step - loss: 0.8103 - accuracy: 0.5619 - val_loss: 1.0261 - val_accuracy: 0.5514\nEpoch 105/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8173 - accuracy: 0.5672 - val_loss: 1.3161 - val_accuracy: 0.5193\nEpoch 106/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8290 - accuracy: 0.5665 - val_loss: 1.2898 - val_accuracy: 0.4807\nEpoch 107/300\n34/34 [==============================] - 29s 868ms/step - loss: 0.8116 - accuracy: 0.5726 - val_loss: 0.8488 - val_accuracy: 0.5563\nEpoch 108/300\n34/34 [==============================] - 29s 865ms/step - loss: 0.8111 - accuracy: 0.5724 - val_loss: 2.4157 - val_accuracy: 0.4164\nEpoch 109/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8274 - accuracy: 0.5626 - val_loss: 0.8977 - val_accuracy: 0.5450\nEpoch 110/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8418 - accuracy: 0.5591 - val_loss: 15.0388 - val_accuracy: 0.3392\nEpoch 111/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8533 - accuracy: 0.5586 - val_loss: 3.8673 - val_accuracy: 0.3666\nEpoch 112/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8157 - accuracy: 0.5731 - val_loss: 1.4170 - val_accuracy: 0.4646\nEpoch 116/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8293 - accuracy: 0.5528 - val_loss: 0.9016 - val_accuracy: 0.5498\nEpoch 117/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8276 - accuracy: 0.5602 - val_loss: 12.9304 - val_accuracy: 0.3441\nEpoch 118/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8202 - accuracy: 0.5628 - val_loss: 2.0704 - val_accuracy: 0.4630\nEpoch 119/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8083 - accuracy: 0.5686 - val_loss: 1.5068 - val_accuracy: 0.4695\nEpoch 120/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8223 - accuracy: 0.5710 - val_loss: 1.0008 - val_accuracy: 0.5273\nEpoch 121/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8192 - accuracy: 0.5717 - val_loss: 1.5221 - val_accuracy: 0.4453\nEpoch 122/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8235 - accuracy: 0.5665 - val_loss: 0.9918 - val_accuracy: 0.4968\nEpoch 123/300\n34/34 [==============================] - 28s 834ms/step - loss: 0.8203 - accuracy: 0.5689 - val_loss: 0.8443 - val_accuracy: 0.5611\nEpoch 124/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8114 - accuracy: 0.5691 - val_loss: 3.2182 - val_accuracy: 0.4132\nEpoch 125/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8086 - accuracy: 0.5658 - val_loss: 1.5620 - val_accuracy: 0.4598\nEpoch 126/300\n34/34 [==============================] - 29s 837ms/step - loss: 0.8173 - accuracy: 0.5628 - val_loss: 1.9641 - val_accuracy: 0.4389\nEpoch 127/300\n34/34 [==============================] - 28s 828ms/step - loss: 0.8213 - accuracy: 0.5661 - val_loss: 4.6651 - val_accuracy: 0.4068\nEpoch 128/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8231 - accuracy: 0.5621 - val_loss: 0.9227 - val_accuracy: 0.5418\nEpoch 129/300\n34/34 [==============================] - 28s 836ms/step - loss: 0.8159 - accuracy: 0.5696 - val_loss: 0.8877 - val_accuracy: 0.5498\nEpoch 130/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8199 - accuracy: 0.5679 - val_loss: 4.1505 - val_accuracy: 0.3505\nEpoch 131/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8262 - accuracy: 0.5658 - val_loss: 0.9928 - val_accuracy: 0.5177\nEpoch 132/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8137 - accuracy: 0.5675 - val_loss: 2.8873 - val_accuracy: 0.4180\nEpoch 133/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8076 - accuracy: 0.5649 - val_loss: 1.5086 - val_accuracy: 0.4646\nEpoch 134/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8216 - accuracy: 0.5693 - val_loss: 5.1780 - val_accuracy: 0.3199\nEpoch 135/300\n34/34 [==============================] - 28s 833ms/step - loss: 0.8522 - accuracy: 0.5574 - val_loss: 2.3789 - val_accuracy: 0.3778\nEpoch 136/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8348 - accuracy: 0.5523 - val_loss: 0.9267 - val_accuracy: 0.5386\nEpoch 137/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8184 - accuracy: 0.5665 - val_loss: 5.0132 - val_accuracy: 0.3971\nEpoch 138/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8265 - accuracy: 0.5609 - val_loss: 3.5620 - val_accuracy: 0.3650\nEpoch 139/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8132 - accuracy: 0.5775 - val_loss: 0.8994 - val_accuracy: 0.5466\nEpoch 140/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8146 - accuracy: 0.5637 - val_loss: 0.9272 - val_accuracy: 0.5322\nEpoch 141/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8133 - accuracy: 0.5668 - val_loss: 7.7237 - val_accuracy: 0.3569\nEpoch 142/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8214 - accuracy: 0.5658 - val_loss: 1.1943 - val_accuracy: 0.5000\nEpoch 143/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8156 - accuracy: 0.5647 - val_loss: 0.9005 - val_accuracy: 0.5450\nEpoch 144/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8165 - accuracy: 0.5658 - val_loss: 4.2333 - val_accuracy: 0.3441\nEpoch 145/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8169 - accuracy: 0.5654 - val_loss: 1.7776 - val_accuracy: 0.4373\nEpoch 146/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8165 - accuracy: 0.5612 - val_loss: 1.4402 - val_accuracy: 0.5273\nEpoch 147/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8103 - accuracy: 0.5686 - val_loss: 0.8945 - val_accuracy: 0.5466\nEpoch 148/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8083 - accuracy: 0.5630 - val_loss: 0.9431 - val_accuracy: 0.5595\nEpoch 149/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8118 - accuracy: 0.5651 - val_loss: 6.4667 - val_accuracy: 0.4035\nEpoch 150/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8136 - accuracy: 0.5607 - val_loss: 0.9299 - val_accuracy: 0.5354\nEpoch 151/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8191 - accuracy: 0.5626 - val_loss: 0.8789 - val_accuracy: 0.5498\nEpoch 152/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8251 - accuracy: 0.5707 - val_loss: 0.9472 - val_accuracy: 0.5402\nEpoch 153/300\n34/34 [==============================] - 28s 839ms/step - loss: 0.8132 - accuracy: 0.5593 - val_loss: 6.0167 - val_accuracy: 0.3328\nEpoch 154/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8162 - accuracy: 0.5619 - val_loss: 1.3750 - val_accuracy: 0.4839\nEpoch 155/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8131 - accuracy: 0.5633 - val_loss: 4.4916 - val_accuracy: 0.3344\nEpoch 156/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8125 - accuracy: 0.5619 - val_loss: 0.8904 - val_accuracy: 0.5418\nEpoch 157/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8353 - accuracy: 0.5621 - val_loss: 6.4280 - val_accuracy: 0.2878\nEpoch 158/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.9604 - accuracy: 0.5360 - val_loss: 12.6456 - val_accuracy: 0.3633\nEpoch 159/300\n34/34 [==============================] - 28s 829ms/step - loss: 0.8577 - accuracy: 0.5642 - val_loss: 3.0094 - val_accuracy: 0.3842\nEpoch 160/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8338 - accuracy: 0.5570 - val_loss: 1.1597 - val_accuracy: 0.5402\nEpoch 161/300\n34/34 [==============================] - 28s 835ms/step - loss: 0.8289 - accuracy: 0.5605 - val_loss: 0.8828 - val_accuracy: 0.5482\nEpoch 162/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8426 - accuracy: 0.5553 - val_loss: 1.5973 - val_accuracy: 0.4904\nEpoch 163/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8229 - accuracy: 0.5710 - val_loss: 1.4614 - val_accuracy: 0.5096\nEpoch 164/300\n34/34 [==============================] - 30s 875ms/step - loss: 0.8185 - accuracy: 0.5614 - val_loss: 3.5281 - val_accuracy: 0.3907\nEpoch 165/300\n34/34 [==============================] - 30s 898ms/step - loss: 0.8205 - accuracy: 0.5567 - val_loss: 42.6969 - val_accuracy: 0.4116\nEpoch 166/300\n34/34 [==============================] - 31s 900ms/step - loss: 0.8248 - accuracy: 0.5661 - val_loss: 1.3859 - val_accuracy: 0.4486\nEpoch 167/300\n34/34 [==============================] - 30s 891ms/step - loss: 0.8230 - accuracy: 0.5644 - val_loss: 0.9319 - val_accuracy: 0.5338\nEpoch 168/300\n34/34 [==============================] - 30s 886ms/step - loss: 0.8143 - accuracy: 0.5630 - val_loss: 1.3471 - val_accuracy: 0.4598\nEpoch 169/300\n34/34 [==============================] - 29s 867ms/step - loss: 0.8264 - accuracy: 0.5691 - val_loss: 1.1856 - val_accuracy: 0.5048\nEpoch 170/300\n34/34 [==============================] - 30s 878ms/step - loss: 0.8193 - accuracy: 0.5644 - val_loss: 0.9287 - val_accuracy: 0.5579\nEpoch 171/300\n34/34 [==============================] - 30s 868ms/step - loss: 0.8204 - accuracy: 0.5623 - val_loss: 2.5724 - val_accuracy: 0.4132\nEpoch 172/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8183 - accuracy: 0.5656 - val_loss: 1.9329 - val_accuracy: 0.4839\nEpoch 173/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8108 - accuracy: 0.5658 - val_loss: 0.8766 - val_accuracy: 0.5466\nEpoch 174/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8130 - accuracy: 0.5661 - val_loss: 0.8926 - val_accuracy: 0.5466\nEpoch 175/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8233 - accuracy: 0.5656 - val_loss: 7.5128 - val_accuracy: 0.1961\nEpoch 176/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8650 - accuracy: 0.5563 - val_loss: 4.1507 - val_accuracy: 0.2910\nEpoch 177/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.8276 - accuracy: 0.5600 - val_loss: 0.8625 - val_accuracy: 0.5627\nEpoch 178/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8219 - accuracy: 0.5700 - val_loss: 1.0315 - val_accuracy: 0.5225\nEpoch 179/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8166 - accuracy: 0.5581 - val_loss: 0.8754 - val_accuracy: 0.5691\nEpoch 180/300\n34/34 [==============================] - 30s 873ms/step - loss: 0.8200 - accuracy: 0.5586 - val_loss: 2.7213 - val_accuracy: 0.4051\nEpoch 181/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.8189 - accuracy: 0.5553 - val_loss: 1.1881 - val_accuracy: 0.5096\nEpoch 182/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8098 - accuracy: 0.5623 - val_loss: 0.8833 - val_accuracy: 0.5386\nEpoch 183/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8080 - accuracy: 0.5703 - val_loss: 3.7301 - val_accuracy: 0.3617\nEpoch 184/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8170 - accuracy: 0.5717 - val_loss: 6.0802 - val_accuracy: 0.4100\nEpoch 185/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8034 - accuracy: 0.5665 - val_loss: 1.3932 - val_accuracy: 0.4823\nEpoch 186/300\n34/34 [==============================] - 29s 869ms/step - loss: 0.8030 - accuracy: 0.5724 - val_loss: 1.7579 - val_accuracy: 0.4968\nEpoch 187/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8145 - accuracy: 0.5710 - val_loss: 0.9257 - val_accuracy: 0.5402\nEpoch 188/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8175 - accuracy: 0.5731 - val_loss: 0.8769 - val_accuracy: 0.5579\nEpoch 189/300\n34/34 [==============================] - 29s 865ms/step - loss: 0.8250 - accuracy: 0.5705 - val_loss: 0.9923 - val_accuracy: 0.5338\nEpoch 190/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8172 - accuracy: 0.5658 - val_loss: 0.8529 - val_accuracy: 0.5563\nEpoch 191/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8103 - accuracy: 0.5714 - val_loss: 1.1624 - val_accuracy: 0.5305\nEpoch 192/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.8083 - accuracy: 0.5700 - val_loss: 0.8315 - val_accuracy: 0.5579\nEpoch 193/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8066 - accuracy: 0.5684 - val_loss: 0.8424 - val_accuracy: 0.5611\nEpoch 194/300\n34/34 [==============================] - 29s 867ms/step - loss: 0.8069 - accuracy: 0.5644 - val_loss: 1.5309 - val_accuracy: 0.4678\nEpoch 195/300\n34/34 [==============================] - 29s 861ms/step - loss: 0.8064 - accuracy: 0.5570 - val_loss: 0.8249 - val_accuracy: 0.5675\nEpoch 196/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8025 - accuracy: 0.5621 - val_loss: 1.1871 - val_accuracy: 0.4984\nEpoch 197/300\n34/34 [==============================] - 29s 862ms/step - loss: 0.8051 - accuracy: 0.5700 - val_loss: 1.2859 - val_accuracy: 0.5016\nEpoch 198/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8059 - accuracy: 0.5593 - val_loss: 3.6686 - val_accuracy: 0.3601\nEpoch 199/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8056 - accuracy: 0.5647 - val_loss: 1.4314 - val_accuracy: 0.4887\nEpoch 200/300\n34/34 [==============================] - 29s 865ms/step - loss: 0.8078 - accuracy: 0.5684 - val_loss: 1.0104 - val_accuracy: 0.5386\nEpoch 201/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8116 - accuracy: 0.5717 - val_loss: 2.4735 - val_accuracy: 0.4984\nEpoch 202/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8114 - accuracy: 0.5696 - val_loss: 1.6355 - val_accuracy: 0.5113\nEpoch 203/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8038 - accuracy: 0.5745 - val_loss: 0.9217 - val_accuracy: 0.5322\nEpoch 204/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8106 - accuracy: 0.5684 - val_loss: 1.1976 - val_accuracy: 0.5193\nEpoch 205/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8083 - accuracy: 0.5682 - val_loss: 1.4125 - val_accuracy: 0.4662\nEpoch 206/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8096 - accuracy: 0.5642 - val_loss: 1.8485 - val_accuracy: 0.4389\nEpoch 207/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8091 - accuracy: 0.5710 - val_loss: 0.9014 - val_accuracy: 0.5450\nEpoch 208/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8120 - accuracy: 0.5623 - val_loss: 5.9075 - val_accuracy: 0.3215\nEpoch 209/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8100 - accuracy: 0.5735 - val_loss: 0.9000 - val_accuracy: 0.5466\nEpoch 210/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8088 - accuracy: 0.5740 - val_loss: 0.9002 - val_accuracy: 0.5386\nEpoch 211/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8126 - accuracy: 0.5591 - val_loss: 9.6040 - val_accuracy: 0.3569\nEpoch 212/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8207 - accuracy: 0.5654 - val_loss: 1.6032 - val_accuracy: 0.4405\nEpoch 213/300\n34/34 [==============================] - 29s 861ms/step - loss: 0.8215 - accuracy: 0.5498 - val_loss: 0.8835 - val_accuracy: 0.5547\nEpoch 214/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8052 - accuracy: 0.5668 - val_loss: 0.8975 - val_accuracy: 0.5305\nEpoch 215/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8078 - accuracy: 0.5663 - val_loss: 1.0569 - val_accuracy: 0.5113\nEpoch 216/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8175 - accuracy: 0.5612 - val_loss: 0.9154 - val_accuracy: 0.5627\nEpoch 217/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8131 - accuracy: 0.5684 - val_loss: 1.8188 - val_accuracy: 0.4325\nEpoch 218/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8186 - accuracy: 0.5668 - val_loss: 4.2271 - val_accuracy: 0.3006\nEpoch 219/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8189 - accuracy: 0.5679 - val_loss: 0.9042 - val_accuracy: 0.5450\nEpoch 220/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8106 - accuracy: 0.5682 - val_loss: 1.0668 - val_accuracy: 0.5016\nEpoch 221/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8110 - accuracy: 0.5686 - val_loss: 0.8739 - val_accuracy: 0.5498\nEpoch 222/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8316 - accuracy: 0.5572 - val_loss: 3.4798 - val_accuracy: 0.4711\nEpoch 223/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8197 - accuracy: 0.5619 - val_loss: 2.3074 - val_accuracy: 0.4855\nEpoch 224/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8109 - accuracy: 0.5726 - val_loss: 1.1608 - val_accuracy: 0.5193\nEpoch 225/300\n34/34 [==============================] - 28s 837ms/step - loss: 0.8110 - accuracy: 0.5679 - val_loss: 1.0827 - val_accuracy: 0.5370\nEpoch 226/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8127 - accuracy: 0.5691 - val_loss: 0.9149 - val_accuracy: 0.5418\nEpoch 227/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8082 - accuracy: 0.5621 - val_loss: 0.8493 - val_accuracy: 0.5691\nEpoch 228/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8054 - accuracy: 0.5693 - val_loss: 0.8684 - val_accuracy: 0.5563\nEpoch 229/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8066 - accuracy: 0.5635 - val_loss: 3.5976 - val_accuracy: 0.4019\nEpoch 230/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8091 - accuracy: 0.5619 - val_loss: 0.9554 - val_accuracy: 0.5402\nEpoch 231/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8015 - accuracy: 0.5782 - val_loss: 1.2358 - val_accuracy: 0.5113\nEpoch 232/300\n34/34 [==============================] - 29s 839ms/step - loss: 0.8116 - accuracy: 0.5784 - val_loss: 3.1243 - val_accuracy: 0.4068\nEpoch 233/300\n34/34 [==============================] - 29s 847ms/step - loss: 0.8136 - accuracy: 0.5696 - val_loss: 1.6423 - val_accuracy: 0.4968\nEpoch 234/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8037 - accuracy: 0.5677 - val_loss: 3.1899 - val_accuracy: 0.4212\nEpoch 235/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8051 - accuracy: 0.5630 - val_loss: 1.0854 - val_accuracy: 0.5322\nEpoch 236/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8092 - accuracy: 0.5691 - val_loss: 1.3721 - val_accuracy: 0.5289\nEpoch 237/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8680 - accuracy: 0.5558 - val_loss: 1.5737 - val_accuracy: 0.4003\nEpoch 238/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8299 - accuracy: 0.5584 - val_loss: 1.7302 - val_accuracy: 0.4823\nEpoch 239/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8122 - accuracy: 0.5679 - val_loss: 3.1120 - val_accuracy: 0.4823\nEpoch 240/300\n34/34 [==============================] - 29s 863ms/step - loss: 0.8280 - accuracy: 0.5703 - val_loss: 1.7850 - val_accuracy: 0.4871\nEpoch 241/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8131 - accuracy: 0.5637 - val_loss: 1.8415 - val_accuracy: 0.4887\nEpoch 242/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8122 - accuracy: 0.5633 - val_loss: 1.4502 - val_accuracy: 0.4695\nEpoch 243/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8114 - accuracy: 0.5588 - val_loss: 1.8875 - val_accuracy: 0.5080\nEpoch 244/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8097 - accuracy: 0.5668 - val_loss: 1.0862 - val_accuracy: 0.5145\nEpoch 245/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8118 - accuracy: 0.5661 - val_loss: 0.9171 - val_accuracy: 0.5498\nEpoch 246/300\n34/34 [==============================] - 29s 878ms/step - loss: 0.8231 - accuracy: 0.5602 - val_loss: 0.8865 - val_accuracy: 0.5434\nEpoch 247/300\n34/34 [==============================] - 30s 871ms/step - loss: 0.8107 - accuracy: 0.5609 - val_loss: 1.3312 - val_accuracy: 0.4984\nEpoch 248/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8063 - accuracy: 0.5679 - val_loss: 2.3794 - val_accuracy: 0.5000\nEpoch 249/300\n34/34 [==============================] - 29s 868ms/step - loss: 0.8068 - accuracy: 0.5526 - val_loss: 1.1932 - val_accuracy: 0.5354\nEpoch 250/300\n34/34 [==============================] - 30s 877ms/step - loss: 0.8090 - accuracy: 0.5591 - val_loss: 2.9620 - val_accuracy: 0.3794\nEpoch 251/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8182 - accuracy: 0.5693 - val_loss: 2.6677 - val_accuracy: 0.3987\nEpoch 252/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8130 - accuracy: 0.5633 - val_loss: 0.8484 - val_accuracy: 0.5498\nEpoch 253/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8049 - accuracy: 0.5689 - val_loss: 0.8716 - val_accuracy: 0.5498\nEpoch 254/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8023 - accuracy: 0.5640 - val_loss: 3.0661 - val_accuracy: 0.4051\nEpoch 255/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8082 - accuracy: 0.5661 - val_loss: 1.4262 - val_accuracy: 0.5418\nEpoch 256/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8083 - accuracy: 0.5644 - val_loss: 4.9830 - val_accuracy: 0.4325\nEpoch 257/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8040 - accuracy: 0.5649 - val_loss: 1.8053 - val_accuracy: 0.4534\nEpoch 258/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8040 - accuracy: 0.5705 - val_loss: 3.2997 - val_accuracy: 0.4469\nEpoch 259/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8107 - accuracy: 0.5712 - val_loss: 1.0607 - val_accuracy: 0.5482\nEpoch 260/300\n34/34 [==============================] - 29s 843ms/step - loss: 0.8091 - accuracy: 0.5700 - val_loss: 6.6282 - val_accuracy: 0.3971\nEpoch 261/300\n34/34 [==============================] - 29s 842ms/step - loss: 0.8043 - accuracy: 0.5756 - val_loss: 0.8673 - val_accuracy: 0.5611\nEpoch 262/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8134 - accuracy: 0.5567 - val_loss: 10.2039 - val_accuracy: 0.3601\nEpoch 263/300\n34/34 [==============================] - 29s 840ms/step - loss: 0.8258 - accuracy: 0.5563 - val_loss: 1.1590 - val_accuracy: 0.4887\nEpoch 264/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8148 - accuracy: 0.5654 - val_loss: 0.9104 - val_accuracy: 0.5498\nEpoch 265/300\n34/34 [==============================] - 29s 841ms/step - loss: 0.8081 - accuracy: 0.5672 - val_loss: 1.4621 - val_accuracy: 0.4518\nEpoch 266/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8024 - accuracy: 0.5766 - val_loss: 1.4496 - val_accuracy: 0.5177\nEpoch 267/300\n34/34 [==============================] - 29s 838ms/step - loss: 0.8048 - accuracy: 0.5684 - val_loss: 3.3985 - val_accuracy: 0.3762\nEpoch 268/300\n34/34 [==============================] - 29s 855ms/step - loss: 0.8086 - accuracy: 0.5752 - val_loss: 2.4679 - val_accuracy: 0.4711\nEpoch 269/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8077 - accuracy: 0.5721 - val_loss: 1.6203 - val_accuracy: 0.4566\nEpoch 270/300\n34/34 [==============================] - 29s 857ms/step - loss: 0.8070 - accuracy: 0.5679 - val_loss: 1.0898 - val_accuracy: 0.5096\nEpoch 271/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8175 - accuracy: 0.5630 - val_loss: 2.5272 - val_accuracy: 0.3537\nEpoch 272/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8138 - accuracy: 0.5619 - val_loss: 4.9394 - val_accuracy: 0.4277\nEpoch 273/300\n34/34 [==============================] - 29s 850ms/step - loss: 0.8023 - accuracy: 0.5738 - val_loss: 6.7105 - val_accuracy: 0.4019\nEpoch 274/300\n34/34 [==============================] - 29s 860ms/step - loss: 0.8062 - accuracy: 0.5707 - val_loss: 0.9056 - val_accuracy: 0.5547\nEpoch 275/300\n34/34 [==============================] - 30s 882ms/step - loss: 0.8159 - accuracy: 0.5635 - val_loss: 0.9326 - val_accuracy: 0.5305\nEpoch 276/300\n34/34 [==============================] - 29s 861ms/step - loss: 0.8150 - accuracy: 0.5707 - val_loss: 2.7306 - val_accuracy: 0.3939\nEpoch 277/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8101 - accuracy: 0.5714 - val_loss: 2.5814 - val_accuracy: 0.4646\nEpoch 278/300\n34/34 [==============================] - 29s 858ms/step - loss: 0.8110 - accuracy: 0.5672 - val_loss: 1.1045 - val_accuracy: 0.5514\nEpoch 279/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8056 - accuracy: 0.5642 - val_loss: 2.7145 - val_accuracy: 0.4293\nEpoch 280/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8177 - accuracy: 0.5642 - val_loss: 0.8220 - val_accuracy: 0.5595\nEpoch 281/300\n34/34 [==============================] - 29s 848ms/step - loss: 0.8037 - accuracy: 0.5763 - val_loss: 0.9012 - val_accuracy: 0.5498\nEpoch 282/300\n34/34 [==============================] - 29s 846ms/step - loss: 0.8028 - accuracy: 0.5717 - val_loss: 2.5228 - val_accuracy: 0.4277\nEpoch 283/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8091 - accuracy: 0.5738 - val_loss: 1.4162 - val_accuracy: 0.4662\nEpoch 284/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8239 - accuracy: 0.5614 - val_loss: 1.0227 - val_accuracy: 0.5354\nEpoch 285/300\n34/34 [==============================] - 29s 849ms/step - loss: 0.8194 - accuracy: 0.5675 - val_loss: 2.2214 - val_accuracy: 0.4920\nEpoch 286/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8273 - accuracy: 0.5616 - val_loss: 3.5376 - val_accuracy: 0.3955\nEpoch 287/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8171 - accuracy: 0.5614 - val_loss: 0.9653 - val_accuracy: 0.5402\nEpoch 288/300\n34/34 [==============================] - 29s 844ms/step - loss: 0.8072 - accuracy: 0.5668 - val_loss: 1.0406 - val_accuracy: 0.5241\nEpoch 289/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8131 - accuracy: 0.5647 - val_loss: 1.6606 - val_accuracy: 0.4614\nEpoch 290/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8049 - accuracy: 0.5791 - val_loss: 0.8430 - val_accuracy: 0.5498\nEpoch 291/300\n34/34 [==============================] - 29s 853ms/step - loss: 0.8030 - accuracy: 0.5742 - val_loss: 3.2434 - val_accuracy: 0.4180\nEpoch 292/300\n34/34 [==============================] - 29s 862ms/step - loss: 0.8112 - accuracy: 0.5675 - val_loss: 4.2863 - val_accuracy: 0.3087\nEpoch 293/300\n34/34 [==============================] - 29s 852ms/step - loss: 0.8214 - accuracy: 0.5663 - val_loss: 0.9129 - val_accuracy: 0.5418\nEpoch 294/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8119 - accuracy: 0.5698 - val_loss: 5.8567 - val_accuracy: 0.3006\nEpoch 295/300\n34/34 [==============================] - 29s 856ms/step - loss: 0.8114 - accuracy: 0.5658 - val_loss: 0.9176 - val_accuracy: 0.5402\nEpoch 296/300\n34/34 [==============================] - 29s 851ms/step - loss: 0.8102 - accuracy: 0.5682 - val_loss: 2.9099 - val_accuracy: 0.4614\nEpoch 297/300\n34/34 [==============================] - 29s 859ms/step - loss: 0.8100 - accuracy: 0.5754 - val_loss: 0.9726 - val_accuracy: 0.5096\nEpoch 298/300\n34/34 [==============================] - 29s 866ms/step - loss: 0.8081 - accuracy: 0.5658 - val_loss: 2.7445 - val_accuracy: 0.4309\nEpoch 299/300\n34/34 [==============================] - 29s 854ms/step - loss: 0.8124 - accuracy: 0.5591 - val_loss: 1.1857 - val_accuracy: 0.5129\nEpoch 300/300\n34/34 [==============================] - 29s 845ms/step - loss: 0.8111 - accuracy: 0.5679 - val_loss: 0.9137 - val_accuracy: 0.5450\nFound 4291 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Final testing accuracy","metadata":{"id":"jRY4ohtKtIA5"}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nimport numpy as np\nfrom sklearn.metrics import classification_report\nimport time\n\ntest_labels = test_dataset.classes\ntest_labels = to_categorical(test_labels, num_classes=9)\n\nstart_time = time.time()\ny_pred = model.predict(test_dataset)\ny_pred_bool = np.argmax(y_pred, axis=1)\nrounded_labels=np.argmax(test_labels, axis=1)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_pred_bool, rounded_labels, digits=4))\nprint(\"Time taken to predict the model \" + str(time.time() - start_time))","metadata":{"id":"hgr6yztNtM5S","execution":{"iopub.status.busy":"2023-10-22T01:32:19.800683Z","iopub.execute_input":"2023-10-22T01:32:19.800997Z","iopub.status.idle":"2023-10-22T01:32:42.229246Z","shell.execute_reply.started":"2023-10-22T01:32:19.800971Z","shell.execute_reply":"2023-10-22T01:32:42.228297Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"34/34 [==============================] - 22s 641ms/step\n              precision    recall  f1-score   support\n\n           0     0.0212    0.1171    0.0359       111\n           1     0.1403    0.1410    0.1406       610\n           2     0.4388    0.1317    0.2026      2043\n           3     0.1387    0.1521    0.1451       559\n           4     0.0750    0.1303    0.0952       353\n           5     0.0016    0.5000    0.0033         2\n           6     0.1419    0.1419    0.1419       613\n\n    accuracy                         0.1368      4291\n   macro avg     0.1368    0.1877    0.1092      4291\nweighted avg     0.2739    0.1368    0.1644      4291\n\nTime taken to predict the model 22.420396089553833\n","output_type":"stream"}]}]}